{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "\n",
    "### 2. Modules and Custom Models\n",
    "\n",
    "- Adding predefined modules from ```torch.nn``` to ```torch.nn.Sequential```.\n",
    "- Creating custom models by inheriting ```torch.nn.Module```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some setup.\n",
    "\n",
    "```torch.nn``` is conventionally imported as ```nn```.  \n",
    "```torch.nn.functional``` is conventionally imported as ```F```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ```torch.nn``` modules and ```torch.nn.Sequential```\n",
    "\n",
    "There are many predefined layers in ```torch.nn```, like conv, linear, pool, ReLU, and more. Also, there are many predefined functions in ```torch.nn.functional```, which overlap a lot with those in ```torch.nn```. The functions are listed in [the Pytorch documentation](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "The difference is that those defined in ```torch.nn``` are essentially wrappers of functions in ```torch.nn.functional``` plus weight initialization and functions such as ```train()```, ```eval()```, or ```parameters()```. Functionals only compute the bare computation of the layer.\n",
    "\n",
    "Here we instantiate a simple two dimensional convolution layer and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((64, 3, 23, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "two_dimensional_conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2)\n",
    "two_dimensional_conv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the same convolution with an all-zero filter. Try to catch the difference between ```torch.nn``` layers and ```torch.nn.functional``` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_conv_result = F.conv2d(input=X, weight=torch.zeros(64, 3, 11, 11), stride=4, padding=2)\n",
    "zero_conv_result_pool = F.max_pool2d(zero_conv_result, kernel_size=3, stride=2)\n",
    "zero_conv_result_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```nn.Sequential```, we can define simple models that do not require much setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2)\n",
    ")\n",
    "\n",
    "simple_model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Models\n",
    "\n",
    "To create custom models, we define a class that inherits ```torch.nn.Module```. Then, all we need to define is the ```__init__``` function and the ```forward``` function.\n",
    "\n",
    "Generally speaking, we define the layers and their initialization in ```__init__``` and define their connections in ```forward```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(64*2*2, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if type(m) in [nn.Conv2d, nn.Linear]:\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                m.bias.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = x.view(-1, 64*2*2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "model(X).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
